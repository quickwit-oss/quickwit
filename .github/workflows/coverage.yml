name: Code coverage

on:
  workflow_dispatch:
  push:
    branches:
      - "main"
      - trigger-coverage-workflow
    paths:
      - "Cargo.lock"
      - "Cargo.toml"
      - "quickwit-*/**"

env:
  QW_S3_ENDPOINT: "http://localhost:4566" # Services are exposed as localhost because we are not running coverage in a container.
  CARGO_INCREMENTAL: 0
  AWS_DEFAULT_REGION: "localhost"
  AWS_ACCESS_KEY_ID: "placeholder"
  AWS_SECRET_ACCESS_KEY: "placeholder"
  TEST_DATABASE_URL: postgres://quickwit-dev:quickwit-dev@localhost:5432/quickwit-metastore-dev

jobs:
  test:
    name: coverage
    runs-on: ubuntu-latest
    # Setting a containing will require to fix the QW_S3_ENDPOINT to http://localstack:4566
    # container: ---
    services:
      localstack:
        image: localstack/localstack:latest
        ports:
          - "4566:4566"
          - "4571:4571"
          - "8080:8080"
        env:
          # `kinesalite` provides a more accurate implementation than
          # the default Kinesis provider (`kinesis-mock`).
          KINESIS_PROVIDER: kinesalite
          SERVICES: kinesis,s3
        options: >-
          --health-cmd "curl -k https://localhost:4566"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      postgres:
        image: postgres:latest
        ports:
          - "5432:5432"
        env:
          POSTGRES_USER: quickwit-dev
          POSTGRES_PASSWORD: quickwit-dev
          POSTGRES_DB: quickwit-metastore-dev
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      kafka-broker:
        image: confluentinc/cp-kafka:6.2.0
        ports:
          - "9092:9092"
          - "9101:9101"
        env:
          KAFKA_BROKER_ID: 1
          KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:29092,PLAINTEXT_HOST://localhost:9092
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
          KAFKA_JMX_PORT: 9101
          KAFKA_JMX_HOSTNAME: localhost
        options: >-
          --health-cmd "cub kafka-ready -b localhost:9092 1 5"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      zookeeper:
        image: confluentinc/cp-zookeeper:6.2.0
        ports:
          - "2181:2181"
        env:
          ZOOKEEPER_CLIENT_PORT: 2181
          ZOOKEEPER_TICK_TIME: 2000
        options: >-
          --health-cmd "cub zk-ready localhost:2181 5"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v3

      - uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/git
            ~/.cargo/registry
            target
          key: ${{ runner.os }}-cargo-test-${{ hashFiles('Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-test-${{ hashFiles('Cargo.lock') }}
            ${{ runner.os }}-cargo-test

      - name: Install awslocal
        run: pip install awscli-local

      - name: Prepare LocalStack S3
        run: ./quickwit-cli/tests/prepare_tests.sh

      # Github actions does not allow services to be started with custom command,
      # so we are running azurite as a container manually.         
      - name: Run azurite service 
        run: DOCKER_SERVICES=azurite make docker-compose-up

      - uses: actions-rs/toolchain@v1
        with:
          toolchain: nightly
          components: clippy, llvm-tools-preview, rustfmt

      - name: Install cargo-llvm-cov
        run: |
          curl -LsSf https://github.com/taiki-e/cargo-llvm-cov/releases/latest/download/cargo-llvm-cov-x86_64-unknown-linux-gnu.tar.gz | \
          tar xzf - -C ~/.cargo/bin

      - uses: Swatinem/rust-cache@v1

      - name: Generate code coverage
        run: |
          cargo +nightly llvm-cov clean --workspace
          cargo +nightly llvm-cov --test failpoints --no-report --features fail/failpoints
          cargo +nightly llvm-cov --no-report --all-features
          cargo +nightly llvm-cov --no-run --lcov --output-path lcov.info

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          token: ${{ secrets.CODECOV_TOKEN }} # not required for public repos
          files: lcov.info
          fail_ci_if_error: true
